ollama at /eagle/EVITA/ollama/bin/ollama
result sophia-gpu-12 index  date Wed Oct 15 12:36:46 AM UTC 2025
Starting inferencing
Ollama Server running on port 11400 with PID ðŸŸ¢ Starting ollama on 127.0.0.1:11400...
âœ… Ollama started (PID 2118705) on 127.0.0.1:11400
  logging to ollama-.log
To connect, run:
  export OLLAMA_HOST=127.0.0.1:11400
  # or use inline: OLLAMA_HOST=127.0.0.1:11400 ollama run llama3
Checking ps to see if it is really running
nsynovic 2118705 11.4  0.0 11232152 37732 ?      Sl   00:36   0:01 ollama serve
nsynovic 2118805  0.0  0.0   6416  2048 ?        S    00:36   0:00 grep ollama
ðŸ’¬ Running aius run-llm-prompt-engineering --db /home/nsynovic/aius_10-11-25.sqlite3 --model 'magistral:24b' --prompt 'uses_dl' --ollama '127.0.0.1:11400' ...
Is Ollama running?
nsynovic 2118569  0.0  0.0  16356  2048 ?        Ss   00:36   0:00 -bash
nsynovic 2118630  0.0  0.0   7376  2048 ?        S    00:36   0:00 /bin/bash -l /var/spool/pbs/mom_priv/jobs/91029.sophia-pbs-01.lab.alcf.anl.gov.SC
nsynovic 2118705  2.7  0.0 12109504 169140 ?     Sl   00:36   0:07 ollama serve
nsynovic 2119317 99.4  0.1 71215076 1416244 ?    Sl   00:36   4:14 /lus/eagle/projects/EVITA/ollama-11.10.0/bin/ollama runner --model /eagle/EVITA/ollama-models/blobs/sha256-641615e9986bc8687f936cd87c586bdd92d338172c4180963080e48b8e84ec36 --port 45127
nsynovic 2135208  0.0  0.0  19208  2048 ?        R    00:41   0:00 ps auxww
nsynovic 2135209  0.0  0.0   6420  2048 ?        S    00:41   0:00 grep ^nsynovic
nsynovic 2135210  0.0  0.0   5600     0 ?        S    00:41   0:00 tee log-.logging
ollama at /eagle/EVITA/ollama/bin/ollama
result sophia-gpu-12 index  date Wed Oct 15 12:41:27 AM UTC 2025
Starting inferencing
Ollama Server running on port 11400 with PID ðŸŸ¢ Starting ollama on 127.0.0.1:11400...
âœ… Ollama started (PID 2138917) on 127.0.0.1:11400
  logging to ollama-.log
To connect, run:
  export OLLAMA_HOST=127.0.0.1:11400
  # or use inline: OLLAMA_HOST=127.0.0.1:11400 ollama run llama3
Checking ps to see if it is really running
nsynovic 2138917 12.6  0.0 11029132 36268 ?      Sl   00:41   0:01 ollama serve
nsynovic 2139411  0.0  0.0   6416  2048 ?        S    00:41   0:00 grep ollama
ðŸ’¬ Running aius run-llm-prompt-engineering --db /home/nsynovic/aius_10-11-25.sqlite3 --model 'magistral:24b' --prompt 'uses_ptms' --ollama '127.0.0.1:11400' ...
ollama at /eagle/EVITA/ollama/bin/ollama
ollama at /eagle/EVITA/ollama/bin/ollama
result sophia-gpu-07 index  date Wed Oct 15 12:43:14 AM UTC 2025
result sophia-gpu-07 index  date Wed Oct 15 12:43:14 AM UTC 2025
Starting inferencing
Starting inferencing
Ollama Server running on port 11400 with PID ðŸŸ¢ Starting ollama on 127.0.0.1:11400...
âœ… Ollama started (PID 1322154) on 127.0.0.1:11400
  logging to ollama-.log
To connect, run:
  export OLLAMA_HOST=127.0.0.1:11400
  # or use inline: OLLAMA_HOST=127.0.0.1:11400 ollama run llama3
Checking ps to see if it is really running
Ollama Server running on port 11400 with PID ðŸŸ¢ Starting ollama on 127.0.0.1:11400...
âœ… Ollama started (PID 1322153) on 127.0.0.1:11400
  logging to ollama-.log
To connect, run:
  export OLLAMA_HOST=127.0.0.1:11400
  # or use inline: OLLAMA_HOST=127.0.0.1:11400 ollama run llama3
Checking ps to see if it is really running
nsynovic 1322153  9.6  0.0 11096976 37788 ?      Sl   00:43   0:00 ollama serve
nsynovic 1322977  0.0  0.0   6416  2048 ?        S    00:43   0:00 grep ollama
nsynovic 1322978  0.0  0.0   6416  2048 ?        S    00:43   0:00 grep ollama
nsynovic 1322153  9.6  0.0 11096976 37788 ?      Sl   00:43   0:00 ollama serve
nsynovic 1322977  0.0  0.0   6416  2048 ?        S    00:43   0:00 grep ollama
nsynovic 1322978  0.0  0.0   6416  2048 ?        S    00:43   0:00 grep ollama
ðŸ’¬ Running aius run-llm-prompt-engineering --db /home/nsynovic/aius_10-11-25.sqlite3 --model 'granite4:small-h' --prompt 'uses_ptms' --ollama '127.0.0.1:11400' ...
ðŸ’¬ Running aius run-llm-prompt-engineering --db /home/nsynovic/aius_10-11-25.sqlite3 --model 'granite4:small-h' --prompt 'uses_dl' --ollama '127.0.0.1:11400' ...
Is Ollama running?
nsynovic 2138518  0.0  0.0  16356  2048 ?        Ss   00:41   0:00 -bash
nsynovic 2138619  0.0  0.0   7376  2048 ?        S    00:41   0:00 /bin/bash -l /var/spool/pbs/mom_priv/jobs/91030.sophia-pbs-01.lab.alcf.anl.gov.SC
nsynovic 2138917  2.8  0.0 12112716 141992 ?     Sl   00:41   0:07 ollama serve
nsynovic 2140602 98.2  0.1 71366680 1414592 ?    Sl   00:41   4:06 /lus/eagle/projects/EVITA/ollama-11.10.0/bin/ollama runner --model /eagle/EVITA/ollama-models/blobs/sha256-641615e9986bc8687f936cd87c586bdd92d338172c4180963080e48b8e84ec36 --port 42155
nsynovic 2155069  0.0  0.0  19208  2048 ?        R    00:45   0:00 ps auxww
nsynovic 2155070  0.0  0.0   6420  2048 ?        S    00:45   0:00 grep ^nsynovic
nsynovic 2155071  0.0  0.0   5600     0 ?        S    00:45   0:00 tee log-.logging
Traceback (most recent call last):
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/urllib3/connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/http/client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/requests/adapters.py", line 644, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/urllib3/connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/urllib3/util/retry.py", line 474, in increment
    raise reraise(type(error), error, _stacktrace)
          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/urllib3/util/util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/urllib3/connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/urllib3/connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/urllib3/connection.py", line 565, in getresponse
    httplib_response = super().getresponse()
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/http/client.py", line 1430, in getresponse
    response.begin()
    ~~~~~~~~~~~~~~^^
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/http/client.py", line 331, in begin
    version, status, reason = self._read_status()
                              ~~~~~~~~~~~~~~~~~^^
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/http/client.py", line 300, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
                             " response")
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/nsynovic/.conda/envs/python/bin/aius", line 10, in <module>
    sys.exit(main())
             ~~~~^^
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/aius/main.py", line 264, in main
    lpe.run()
    ~~~~~~~^^
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/aius/llm_prompt_engineering.py", line 92, in run
    resp: Response = post(
                     ~~~~^
        url=self.ollama_uri,
        ^^^^^^^^^^^^^^^^^^^^
        timeout=aius.POST_TIMEOUT,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
        json=json_data,
        ^^^^^^^^^^^^^^^
    )
    ^
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/requests/api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/requests/api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/nsynovic/.conda/envs/python/lib/python3.13/site-packages/requests/adapters.py", line 659, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
Is Ollama running?
nsynovic 1320270  0.0  0.0  16356  2048 ?        Ss   00:43   0:00 -bash
nsynovic 1321948  0.0  0.0   7376  2048 ?        S    00:43   0:00 /bin/bash -l /var/spool/pbs/mom_priv/jobs/91031.sophia-pbs-01.lab.alcf.anl.gov.SC
nsynovic 1322153  0.8  0.0 12219576 160912 ?     Sl   00:43   0:07 ollama serve
nsynovic 1324963 1459  0.0      0     0 ?        Zl   00:43 207:27 [ollama] <defunct>
nsynovic 1773622  0.0  0.0  19208  2048 ?        R    00:58   0:00 ps auxww
nsynovic 1773623  0.0  0.0   6420  2048 ?        S    00:58   0:00 grep ^nsynovic
nsynovic 1773624  0.0  0.0   5600     0 ?        S    00:58   0:00 tee log-.logging
ollama at /eagle/EVITA/ollama/bin/ollama
result sophia-gpu-12 index  date Wed Oct 15 12:58:57 AM UTC 2025
Starting inferencing
Ollama Server running on port 11400 with PID ðŸŸ¢ Starting ollama on 127.0.0.1:11400...
âœ… Ollama started (PID 2206967) on 127.0.0.1:11400
  logging to ollama-.log
To connect, run:
  export OLLAMA_HOST=127.0.0.1:11400
  # or use inline: OLLAMA_HOST=127.0.0.1:11400 ollama run llama3
Checking ps to see if it is really running
nsynovic 2206967 11.6  0.0 11231896 37692 ?      Sl   00:58   0:01 ollama serve
nsynovic 2208620  0.0  0.0   6416  2048 ?        S    00:59   0:00 grep ollama
ðŸ’¬ Running aius run-llm-prompt-engineering --db /home/nsynovic/aius_10-11-25.sqlite3 --model 'granite4:small-h' --prompt 'uses_dl' --ollama '127.0.0.1:11400' ...
Is Ollama running?
nsynovic 2206822  0.0  0.0  16356  2048 ?        Ss   00:58   0:00 -bash
nsynovic 2206884  0.0  0.0   7376  2048 ?        S    00:58   0:00 /bin/bash -l /var/spool/pbs/mom_priv/jobs/91035.sophia-pbs-01.lab.alcf.anl.gov.SC
nsynovic 2206967  1.0  0.0 12185828 137488 ?     Sl   00:58   0:05 ollama serve
nsynovic 2208728 1529  0.1 107384168 1212796 ?   Sl   00:59 143:45 /lus/eagle/projects/EVITA/ollama-11.10.0/bin/ollama runner --model /eagle/EVITA/ollama-models/blobs/sha256-1153a8cd1daecbbd19161f6f8580ebfde1a2834b24b6f3075ff2e81b58101afe --port 38519
nsynovic 2512256  0.0  0.0  19208  2048 ?        R    01:08   0:00 ps auxww
nsynovic 2512257  0.0  0.0   6420  2048 ?        S    01:08   0:00 grep ^nsynovic
nsynovic 2512258  0.0  0.0   5600     0 ?        S    01:08   0:00 tee log-.logging
ollama at /eagle/EVITA/ollama/bin/ollama
result sophia-gpu-12 index  date Wed Oct 15 01:08:46 AM UTC 2025
Starting inferencing
Ollama Server running on port 11400 with PID ðŸŸ¢ Starting ollama on 127.0.0.1:11400...
âœ… Ollama started (PID 2515863) on 127.0.0.1:11400
  logging to ollama-.log
To connect, run:
  export OLLAMA_HOST=127.0.0.1:11400
  # or use inline: OLLAMA_HOST=127.0.0.1:11400 ollama run llama3
Checking ps to see if it is really running
nsynovic 2515863 11.5  0.0 11232920 37692 ?      Sl   01:08   0:01 ollama serve
nsynovic 2515902  0.0  0.0   6416  2048 ?        S    01:08   0:00 grep ollama
ðŸ’¬ Running aius run-llm-prompt-engineering --db /home/nsynovic/aius_10-11-25.sqlite3 --model 'granite4:small-h' --prompt 'uses_ptms' --ollama '127.0.0.1:11400' ...
Is Ollama running?
nsynovic 2515733  0.0  0.0  16356  2048 ?        Ss   01:08   0:00 -bash
nsynovic 2515795  0.0  0.0   7376  2048 ?        S    01:08   0:00 /bin/bash -l /var/spool/pbs/mom_priv/jobs/91036.sophia-pbs-01.lab.alcf.anl.gov.SC
nsynovic 2515863  1.1  0.0 12254416 142652 ?     Sl   01:08   0:05 ollama serve
nsynovic 2515950 1426  0.1 107392724 1210292 ?   Sl   01:08 115:46 /lus/eagle/projects/EVITA/ollama-11.10.0/bin/ollama runner --model /eagle/EVITA/ollama-models/blobs/sha256-1153a8cd1daecbbd19161f6f8580ebfde1a2834b24b6f3075ff2e81b58101afe --port 45343
nsynovic 2760406  0.0  0.0  19208  2048 ?        R    01:17   0:00 ps auxww
nsynovic 2760407  0.0  0.0   6420  2048 ?        S    01:17   0:00 grep ^nsynovic
nsynovic 2760408  0.0  0.0   5600     0 ?        S    01:17   0:00 tee log-.logging
ollama at /eagle/EVITA/ollama/bin/ollama
result sophia-gpu-12 index  date Wed Oct 15 02:11:13 AM UTC 2025
Starting inferencing
Ollama Server running on port 11400 with PID ðŸŸ¢ Starting ollama on 127.0.0.1:11400...
âœ… Ollama started (PID 2969010) on 127.0.0.1:11400
  logging to ollama-.log
To connect, run:
  export OLLAMA_HOST=127.0.0.1:11400
  # or use inline: OLLAMA_HOST=127.0.0.1:11400 ollama run llama3
Checking ps to see if it is really running
nsynovic 2969010  0.9  0.0 2078760 18432 ?       Sl   02:11   0:00 ollama serve
nsynovic 2969040  4.5  0.0 4189084 106496 ?      Sl   02:11   0:00 /lus/eagle/projects/EVITA/ollama-12.5.0/bin/ollama runner --ollama-engine --port 44779
nsynovic 2969055  0.0  0.0   6416  2048 ?        S    02:11   0:00 grep ollama
ðŸ’¬ Running aius run-llm-prompt-engineering --db /home/nsynovic/aius_10-11-25.sqlite3 --model 'gpt-oss:20b' --prompt 'uses_dl' --ollama '127.0.0.1:11400' ...
Is Ollama running?
nsynovic 2968882  0.0  0.0  16356  2048 ?        Ss   02:11   0:00 -bash
nsynovic 2968942  0.0  0.0   7376  2048 ?        S    02:11   0:00 /bin/bash -l /var/spool/pbs/mom_priv/jobs/91044.sophia-pbs-01.lab.alcf.anl.gov.SC
nsynovic 2969010  7.8  0.0 3907380 125436 ?      Sl   02:11   0:10 ollama serve
nsynovic 2969305  166  0.3 148652308 3929236 ?   Sl   02:11   3:15 /lus/eagle/projects/EVITA/ollama-12.5.0/bin/ollama runner --ollama-engine --model /eagle/EVITA/ollama-models/blobs/sha256-b112e727c6f18875636c56a779790a590d705aec9e1c0eb5a97d51fc2a778583 --port 35049
nsynovic 2976692  0.0  0.0  19208  2048 ?        R    02:13   0:00 ps auxww
nsynovic 2976693  0.0  0.0   6420  2048 ?        S    02:13   0:00 grep ^nsynovic
nsynovic 2976694  0.0  0.0   5600     0 ?        S    02:13   0:00 tee log-.logging
ollama at /eagle/EVITA/ollama/bin/ollama
result sophia-gpu-12 index  date Wed Oct 15 02:13:38 AM UTC 2025
Starting inferencing
Ollama Server running on port 11400 with PID ðŸŸ¢ Starting ollama on 127.0.0.1:11400...
âœ… Ollama started (PID 2981572) on 127.0.0.1:11400
  logging to ollama-.log
To connect, run:
  export OLLAMA_HOST=127.0.0.1:11400
  # or use inline: OLLAMA_HOST=127.0.0.1:11400 ollama run llama3
Checking ps to see if it is really running
nsynovic 2981572  0.4  0.0 2281268 18432 ?       Sl   02:13   0:00 ollama serve
nsynovic 2981747  0.0  0.0   6416  2048 ?        S    02:13   0:00 grep ollama
ðŸ’¬ Running aius run-llm-prompt-engineering --db /home/nsynovic/aius_10-11-25.sqlite3 --model 'gpt-oss:20b' --prompt 'uses_ptms' --ollama '127.0.0.1:11400' ...
Is Ollama running?
nsynovic 2981441  0.0  0.0  16356  2048 ?        Ss   02:13   0:00 -bash
nsynovic 2981503  0.0  0.0   7376  2048 ?        S    02:13   0:00 /bin/bash -l /var/spool/pbs/mom_priv/jobs/91045.sophia-pbs-01.lab.alcf.anl.gov.SC
nsynovic 2981572  9.0  0.0 3973432 116544 ?      Sl   02:13   0:10 ollama serve
nsynovic 2981865  189  0.3 148682976 3927616 ?   Sl   02:13   3:12 /lus/eagle/projects/EVITA/ollama-12.5.0/bin/ollama runner --ollama-engine --model /eagle/EVITA/ollama-models/blobs/sha256-b112e727c6f18875636c56a779790a590d705aec9e1c0eb5a97d51fc2a778583 --port 44455
nsynovic 2988936  0.0  0.0  19208  2048 ?        R    02:15   0:00 ps auxww
nsynovic 2988937  0.0  0.0   6420  2048 ?        S    02:15   0:00 grep ^nsynovic
nsynovic 2988938  0.0  0.0   5600     0 ?        S    02:15   0:00 tee log-.logging
